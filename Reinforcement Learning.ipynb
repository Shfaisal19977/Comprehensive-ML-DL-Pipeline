{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNW8CVqFPNZGO7EY6JovVPu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"eywWRsHQOCiF"},"outputs":[],"source":["import gym\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","\n","# Q-Learning Agent Class\n","class QLearningAgent:\n","    def __init__(self, state_size, action_size, learning_rate=0.001, gamma=0.95):\n","        self.model = self._build_model(state_size, action_size, learning_rate)\n","        self.gamma = gamma\n","\n","    def _build_model(self, state_size, action_size, learning_rate):\n","        model = tf.keras.Sequential([\n","            layers.Dense(24, input_dim=state_size, activation='relu'),\n","            layers.Dense(24, activation='relu'),\n","            layers.Dense(action_size, activation='linear')\n","        ])\n","        model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate), loss='mse')\n","        return model\n","\n","    def train(self, X, y):\n","        return self.model.fit(X, y, verbose=0)\n","\n","    def predict(self, state):\n","        return self.model.predict(state)\n","\n","# Deep Q-Learning Function\n","def deep_q_learning(env_name, episodes=1000, learning_rate=0.001):\n","    env = gym.make(env_name)\n","    state_size = env.observation_space.shape[0]\n","    action_size = env.action_space.n\n","\n","    agent = QLearningAgent(state_size, action_size, learning_rate)\n","\n","    for episode in range(episodes):\n","        state = env.reset()\n","        state = np.reshape(state, [1, state_size])\n","\n","        for time in range(500):\n","            action = np.argmax(agent.predict(state))\n","            next_state, reward, done, _ = env.step(action)\n","            next_state = np.reshape(next_state, [1, state_size])\n","\n","            target = reward + agent.gamma * np.max(agent.predict(next_state))\n","            target_f = agent.predict(state)\n","            target_f[0][action] = target\n","\n","            agent.train(state, target_f)\n","            state = next_state\n","\n","            if done:\n","                break\n","\n","# Sample usage with environment\n","# deep_q_learning(env_name='CartPole-v1', episodes=1000)\n"]}]}