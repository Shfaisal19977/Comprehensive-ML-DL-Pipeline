{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPYQrxfb5LbsymMSO7v6DdU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"u1EWsx74NKkd"},"outputs":[],"source":["import tensorflow as tf\n","\n","# Custom Model Class\n","class CustomModel(tf.keras.Model):\n","    def __init__(self, n_classes):\n","        super().__init__()\n","        self.hidden1 = tf.keras.layers.Dense(128, activation='relu')\n","        self.hidden2 = tf.keras.layers.Dense(64, activation='relu')\n","        self.output_layer = tf.keras.layers.Dense(n_classes, activation='softmax')\n","\n","    def call(self, inputs):\n","        x = self.hidden1(inputs)\n","        x = self.hidden2(x)\n","        return self.output_layer(x)\n","\n","# Custom Training Loop\n","def train_model(model, X_train, y_train, X_val, y_val, learning_rate=0.001, epochs=10, batch_size=32):\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n","    train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n","    val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n","\n","    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(buffer_size=1024).batch(batch_size)\n","    val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batch_size)\n","\n","    for epoch in range(epochs):\n","        print(f\"\\nStart of epoch {epoch}\")\n","\n","        # Training loop\n","        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n","            with tf.GradientTape() as tape:\n","                logits = model(x_batch_train, training=True)\n","                loss_value = loss_fn(y_batch_train, logits)\n","\n","            grads = tape.gradient(loss_value, model.trainable_weights)\n","            optimizer.apply_gradients(zip(grads, model.trainable_weights))\n","\n","            train_acc_metric.update_state(y_batch_train, logits)\n","\n","        # Display metrics\n","        train_acc = train_acc_metric.result()\n","        print(f\"Training acc over epoch: {float(train_acc):.4f}\")\n","\n","        train_acc_metric.reset_states()\n","\n","        # Validation loop\n","        for x_batch_val, y_batch_val in val_dataset:\n","            val_logits = model(x_batch_val, training=False)\n","            val_acc_metric.update_state(y_batch_val, val_logits)\n","\n","        val_acc = val_acc_metric.result()\n","        print(f\"Validation acc: {float(val_acc):.4f}\")\n","        val_acc_metric.reset_states()\n","\n","# Usage Example Function\n","def run_custom_training(X, y, input_shape=(10,), n_classes=10, epochs=10):\n","    X_train, X_test, y_train, y_test = prepare_data(X, y)\n","\n","    custom_model = CustomModel(n_classes=n_classes)\n","    train_model(custom_model, X_train, y_train, X_test, y_test, epochs=epochs)\n","\n","# Sample usage with custom dataset\n","# run_custom_training(X, y, input_shape=(X_train.shape[1],), n_classes=10, epochs=20)\n"]}]}